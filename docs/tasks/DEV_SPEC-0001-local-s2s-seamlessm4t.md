# Requirements Analysis & Specification: Local Speech-to-Speech Translation

This document details the requirements for the Local Speech-to-Speech (S2S) translation system, as described in **ADR-0001**.

---

### 1. Detailed Requirements Specification

The system aims to provide a direct, end-to-end translation pipeline from German speech to English speech, running entirely locally on a Windows 11 machine.

#### 1.1 Functional Requirements
*   **Audio Input:** The system must capture raw audio data from the user's microphone via a browser-based frontend.
*   **Streaming Protocol:** Audio data must be transmitted to the backend via WebSockets for low-overhead communication.
*   **Segmentation:** The backend must utilize **Silero VAD** (Voice Activity Detection) to identify sentence boundaries (speech pauses). Translation triggers only after a completed sentence is detected.
*   **Translation Engine:** The core translation must be performed by **Meta's SeamlessM4T v2** model.
    *   Source Language: German (`deu`).
    *   Target Language: English (`eng`).
*   **Audio Output:** The translated audio (generated by the model) must be sent back to the client via the same WebSocket connection and played automatically.
*   **Hardware Abstraction:** The system must automatically detect the available hardware:
    *   Use NVIDIA GPU (CUDA) if available for low latency.
    *   Fallback to CPU if no GPU is found, logging a warning about expected high latency.

#### 1.2 Non-Functional Requirements
*   **Platform:** Windows 11.
*   **Local Execution:** No external APIs (OpenAI, Google, etc.) allowed. All models must be downloaded and cached locally.
*   **Latency:**
    *   **GPU Mode:** Target < 2 seconds processing time per sentence.
    *   **CPU Mode:** Functional but no strict latency limit (acknowledged to be slow, potentially > 5s).
*   **Code Quality:** Strict adherence to `docs/CODING_STYLE.md`.

---

### 2. User Stories & Acceptance Criteria

**Epic: Core Speech-to-Speech Pipeline**

*   **User Story 1: Hardware-Aware Startup**
    *   **As a** developer/user,
    *   **I want** the application to auto-detect my hardware on startup,
    *   **So that** I can run it on my laptop (CPU) or workstation (GPU) without manual configuration changes.
    *   **Acceptance Criteria:**
        *   Application starts without crashing on a machine with only CPU.
        *   Application logs "Running on CPU" or "Running on CUDA:0" clearly to the console.
        *   Model loads successfully in the appropriate precision (float32 for CPU, float16/bfloat16 for GPU).

*   **User Story 2: Speech Segmentation**
    *   **As a** user,
    *   **I want** the system to wait until I finish a sentence before translating,
    *   **So that** the translation has enough context to be accurate.
    *   **Acceptance Criteria:**
        *   System uses VAD to detect silence duration > 500ms (configurable).
        *   Audio is buffered until silence is detected.
        *   Console logs show "Sentence detected, starting translation...".

*   **User Story 3: German-to-English Translation**
    *   **As a** user,
    *   **I want** to hear an English version of my spoken German sentence,
    *   **So that** I can verify the translation capability.
    *   **Acceptance Criteria:**
        *   Input: "Hallo, wie geht es dir?" (German Audio).
        *   Output: Audio playing "Hello, how are you?" (English Audio).
        *   The output audio is intelligible.

*   **User Story 4: Basic Frontend Interface**
    *   **As a** user,
    *   **I want** a simple web button to start/stop the microphone,
    *   **So that** I can control when the system listens.
    *   **Acceptance Criteria:**
        *   A "Start Recording" button establishes the WebSocket connection.
        *   A visual indicator shows when the microphone is active.
        *   Audio playback starts automatically when data is received from the server.

---

### 3. Prioritization and Dependency Analysis

*   **Prioritization (MoSCoW Method):**
    *   **Must-Have (MVP):**
        *   Hardware detection logic (CPU/GPU).
        *   FastAPI WebSocket server setup.
        *   Silero VAD integration for segmentation.
        *   SeamlessM4T v2 integration (Model loading & Inference).
        *   Basic HTML/JS Client for Audio I/O.
    *   **Should-Have:**
        *   Configuration file (YAML/JSON) to switch model sizes (`medium` vs `large`) easily.
        *   Visual feedback in frontend (e.g., "Processing...", "Playing...").
    *   **Could-Have:**
        *   Support for YouTube URL audio input (via `yt-dlp`).
        *   Docker support.
    *   **Won't-Have (in this increment):**
        *   RAG / Terminology injection.
        *   Real-time streaming (overlapping audio).
        *   User authentication.

*   **Dependencies:**
    1.  **Hardware Check:** Must be implemented first to ensure the dev environment is supported.
    2.  **Model Loading:** Depends on `transformers` and `torch` installation.
    3.  **VAD Logic:** Must be tuned before connecting the Translation model, otherwise, the model receives noise or incomplete words.

---

### 4. Product Backlog

| ID | Epic | User Story / Task | Priority |
| :-- | :--- | :--- | :--- |
| PB-001 | Infra | **Setup Project Structure**: `pyproject.toml`, dependencies (`torch`, `transformers`, `fastapi`, `uvicorn`, `silero-vad`, `numpy`). | High |
| PB-002 | Backend | **Implement Device Manager**: Class to handle `cuda` vs `cpu` detection and model loading. | High |
| PB-003 | Backend | **Implement VAD Processor**: Logic to buffer audio chunks and detect silence using Silero. | High |
| PB-004 | Backend | **Implement Translator Engine**: Wrapper around SeamlessM4T `generate_speech` method. | High |
| PB-005 | Backend | **WebSocket Endpoint**: Fast API route handling the orchestration (Receive -> VAD -> Translate -> Send). | High |
| PB-006 | Frontend | **Basic Client**: HTML/JS to capture Mic (MediaRecorder API) and play PCM/WAV response. | High |
| PB-007 | Config | **Configuration System**: Add ability to switch model size (`facebook/seamless-m4t-v2-large` vs `medium`). | Medium |
| PB-008 | Test | **End-to-End Test**: Verify the full loop with a pre-recorded audio file. | Medium |

---

### 5. Definition of Done (DoD)

A Product Backlog Item is considered "Done" when all of the following criteria are met:

*   **Code Quality:** The code is written and formatted according to the guidelines in `docs/CODING_STYLE.md` (Checked via `black .`, `ruff check .`).
*   **Tests:**
    *   Backend logic (VAD buffer, Model loading) is covered by unit tests.
    *   The WebSocket endpoint is verified by a basic connection test.
*   **Acceptance Criteria:** All acceptance criteria defined for the story have been met.
*   **Local verification:** The feature runs on the local Windows 11 machine (CPU or GPU).
*   **Documentation:** `CHANGELOG.md` is updated (if applicable).
