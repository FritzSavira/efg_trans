<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>S2S Translator</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        body { background-color: #f8f9fa; }
        .container { max-width: 600px; margin-top: 50px; }
        .status-dot { height: 10px; width: 10px; background-color: #bbb; border-radius: 50%; display: inline-block; }
        .status-online { background-color: #28a745; }
        #status-text { font-weight: bold; }
        .log-area { height: 200px; overflow-y: auto; background: #eee; padding: 10px; font-family: monospace; font-size: 0.8rem; border-radius: 5px; }
    </style>
</head>
<body>
    <div class="container bg-white p-5 shadow rounded">
        <h2 class="mb-4 text-center">Multi-Language S2S Translator</h2>

        <div class="alert alert-info text-center" role="alert">
            üéß <strong>Bitte Kopfh√∂rer verwenden!</strong><br>
            Der "Continuous Mode" erfordert Kopfh√∂rer, um ein Echo zu vermeiden.
        </div>
        
        <div class="mb-3">
            <label for="language-select" class="form-label fw-bold">Zielsprache w√§hlen:</label>
            <select class="form-select mb-3" id="language-select">
                <option value="eng" selected>Englisch (English)</option>
                <option value="spa">Spanisch (Espa√±ol)</option>
                <option value="por">Portugiesisch (Portugu√™s)</option>
                <option value="arb">Arabisch (ÿßŸÑÿπÿ±ÿ®Ÿäÿ©)</option>
                <option value="pes">Farsi (Persisch)</option>
                <option value="cmn">Mandarin (Chinesisch)</option>
            </select>
        </div>

        <div class="mb-3">
            <label for="silence-slider" class="form-label fw-bold">Antwort-Geschwindigkeit (Pause): <span id="silence-val" class="badge bg-secondary">500 ms</span></label>
            <input type="range" class="form-range" id="silence-slider" min="200" max="2000" step="100" value="500">
            <div class="form-text">Kleinerer Wert = Schnellere Antwort (gut f√ºr kurze S√§tze). Gr√∂√üerer Wert = Mehr Zeit zum Nachdenken.</div>
        </div>

        <div class="mb-4">
            <span class="status-dot" id="dot"></span>
            Status: <span id="status-text">Disconnected</span>
        </div>

        <div class="d-grid gap-2 mb-4">
            <div class="d-flex gap-2">
                <button id="record-btn" class="btn btn-primary flex-grow-1">Start Recording</button>
                <button id="upload-btn" class="btn btn-secondary">üìÅ Upload File</button>
                <input type="file" id="file-input" accept=".wav,.mp3,.ogg,.webm,.m4a" style="display: none;">
            </div>
        </div>

        <div class="log-area mb-2" id="logs">
            Welcome. Click Start to begin.
        </div>
    </div>

    <script>
        let ws;
        let audioContext;
        let scriptProcessor;
        let input;
        const recordBtn = document.getElementById('record-btn');
        const statusText = document.getElementById('status-text');
        const dot = document.getElementById('dot');
        const logs = document.getElementById('logs');
        const languageSelect = document.getElementById('language-select');
        const silenceSlider = document.getElementById('silence-slider');
        const silenceVal = document.getElementById('silence-val');
        const uploadBtn = document.getElementById('upload-btn');
        const fileInput = document.getElementById('file-input');
        let isFileStreaming = false;

        silenceSlider.oninput = function() {
            silenceVal.textContent = this.value + ' ms';
        }

        silenceSlider.onchange = function() {
            const val = parseInt(this.value);
            addLog(`Setting silence timeout to ${val}ms...`);
            if (ws && ws.readyState === WebSocket.OPEN) {
                const msg = JSON.stringify({type: "config", min_silence_ms: val});
                ws.send(msg);
            }
        }
        
        uploadBtn.onclick = () => fileInput.click();

        fileInput.onchange = async (e) => {
             const file = e.target.files[0];
             if (!file) return;
             await handleFileUpload(file);
             fileInput.value = ''; 
        };

        async function handleFileUpload(file) {
             if (ws && ws.readyState === WebSocket.OPEN) {
                 stopRecording();
                 // Give it a moment to close
                 await new Promise(r => setTimeout(r, 500));
             }
             
             addLog(`Processing file: ${file.name} (${(file.size/1024).toFixed(1)} KB)...`);
             
             try {
                 const arrayBuffer = await file.arrayBuffer();
                 const tempCtx = new (window.AudioContext || window.webkitAudioContext)();
                 const audioBuffer = await tempCtx.decodeAudioData(arrayBuffer);
                 
                 addLog(`Decoded. Original Rate: ${audioBuffer.sampleRate}Hz, Duration: ${audioBuffer.duration.toFixed(2)}s`);
                 
                 const resampledBuffer = await resampleTo16k(audioBuffer);
                 addLog(`Resampled to 16000Hz.`);
                 
                 await connectWebSocket();
                 streamAudioFile(resampledBuffer);
                 
             } catch (err) {
                 addLog('Error processing file: ' + err);
             }
        }
        
        async function resampleTo16k(audioBuffer) {
            if (audioBuffer.sampleRate === 16000) return audioBuffer;
            const offlineCtx = new OfflineAudioContext(1, audioBuffer.duration * 16000, 16000);
            const source = offlineCtx.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(offlineCtx.destination);
            source.start(0);
            return await offlineCtx.startRendering();
        }
        
        async function connectWebSocket() {
            return new Promise((resolve, reject) => {
                const targetLang = languageSelect.value;
                const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
                ws = new WebSocket(`${protocol}//${window.location.host}/ws/translate?tgt_lang=${targetLang}`);
                ws.binaryType = 'arraybuffer';
                
                ws.onopen = () => {
                    statusText.textContent = `File Mode (${targetLang})`;
                    dot.classList.add('status-online');
                    recordBtn.textContent = 'Stop Playback';
                    recordBtn.classList.replace('btn-primary', 'btn-danger');
                    languageSelect.disabled = true;
                    uploadBtn.disabled = true;
                    addLog('Connected to server.');
                    resolve();
                };
                
                ws.onerror = (err) => reject(err);
                
                ws.onmessage = async (event) => {
                    addLog('Received translation. Enqueueing...');
                    audioQueue.enqueue(event.data);
                };
                
                ws.onclose = () => {
                     stopRecording();
                };
            });
        }

        async function streamAudioFile(audioBuffer) {
            isFileStreaming = true;
            const rawData = audioBuffer.getChannelData(0); 
            const chunkSize = 4096; // ~256ms
            let offset = 0;
            
            addLog('Starting streaming...');
            
            while (offset < rawData.length && isFileStreaming && ws && ws.readyState === WebSocket.OPEN) {
                const end = Math.min(offset + chunkSize, rawData.length);
                const chunk = rawData.slice(offset, end);
                
                ws.send(chunk.buffer);
                
                offset += chunkSize;
                await new Promise(r => setTimeout(r, 250));
            }
            
            addLog('File streaming finished.');
            isFileStreaming = false;
        }

        class AudioQueue {
            constructor() {
                this.queue = [];
                this.isPlaying = false;
            }

            enqueue(arrayBuffer) {
                this.queue.push(arrayBuffer);
                this.process();
            }

            async process() {
                if (this.isPlaying || this.queue.length === 0) {
                    return;
                }

                this.isPlaying = true;
                const nextBuffer = this.queue.shift();

                try {
                    await this.play(nextBuffer);
                } catch (e) {
                    addLog('Error playing audio from queue: ' + e);
                    this.isPlaying = false;
                    this.process(); // Try next
                }
            }

            async play(arrayBuffer) {
                if (!audioContext) audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
                
                // Decode asynchronously
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);
                
                return new Promise((resolve) => {
                    source.onended = () => {
                        this.isPlaying = false;
                        resolve();
                        this.process(); // Trigger next item
                    };
                    source.start();
                    addLog(`Playing audio (${audioBuffer.duration.toFixed(2)}s) [Queue: ${this.queue.length}]`);
                });
            }

            clear() {
                this.queue = [];
                this.isPlaying = false;
            }
        }

        const audioQueue = new AudioQueue();

        function addLog(msg) {
            const div = document.createElement('div');
            div.textContent = `[${new Date().toLocaleTimeString()}] ${msg}`;
            logs.appendChild(div);
            logs.scrollTop = logs.scrollHeight;
        }

        recordBtn.onclick = async () => {
            if (ws && ws.readyState === WebSocket.OPEN) {
                stopRecording();
                return;
            }
            startRecording();
        };

        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                // Initialize WebSocket with language parameter
                const targetLang = languageSelect.value;
                const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
                ws = new WebSocket(`${protocol}//${window.location.host}/ws/translate?tgt_lang=${targetLang}`);
                ws.binaryType = 'arraybuffer';

                ws.onopen = () => {
                    statusText.textContent = `Online (${targetLang})`;
                    dot.classList.add('status-online');
                    recordBtn.textContent = 'Stop Recording';
                    recordBtn.classList.replace('btn-primary', 'btn-danger');
                    languageSelect.disabled = true;
                    uploadBtn.disabled = true;
                    addLog(`Connected to server. Target: ${targetLang}`);
                    setupAudioProcessing(stream);
                };

                ws.onmessage = async (event) => {
                    addLog('Received translation. Enqueueing...');
                    audioQueue.enqueue(event.data);
                };

                ws.onclose = () => {
                    addLog('Disconnected from server.');
                    stopRecording();
                };

            } catch (err) {
                addLog('Error accessing microphone: ' + err);
            }
        }

        function stopRecording() {
            isFileStreaming = false; // Stop file loop
            if (scriptProcessor) {
                scriptProcessor.disconnect();
                scriptProcessor = null;
            }
            if (input) {
                input.disconnect();
                input = null;
            }
            if (ws) {
                ws.close();
                ws = null;
            }
            audioQueue.clear();
            statusText.textContent = 'Disconnected';
            dot.classList.remove('status-online');
            recordBtn.textContent = 'Start Recording';
            recordBtn.classList.replace('btn-danger', 'btn-primary');
            languageSelect.disabled = false;
            uploadBtn.disabled = false;
        }

        function setupAudioProcessing(stream) {
            // Use native sample rate to avoid browser resampling issues/artifacts
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const sourceSampleRate = audioContext.sampleRate;
            const targetSampleRate = 16000;
            
            addLog(`Microphone Native Rate: ${sourceSampleRate}Hz. Downsampling to ${targetSampleRate}Hz...`);
            
            input = audioContext.createMediaStreamSource(stream);
            // Buffer size 4096 is fine
            scriptProcessor = audioContext.createScriptProcessor(4096, 1, 1);

            scriptProcessor.onaudioprocess = (e) => {
                if (ws && ws.readyState === WebSocket.OPEN) {
                    const inputData = e.inputBuffer.getChannelData(0);
                    
                    // Manual Downsampling
                    if (sourceSampleRate === targetSampleRate) {
                         ws.send(inputData.buffer);
                    } else {
                        // Simple decimation
                        const ratio = sourceSampleRate / targetSampleRate;
                        const newLength = Math.floor(inputData.length / ratio);
                        const result = new Float32Array(newLength);
                        
                        for (let i = 0; i < newLength; i++) {
                            // Basic linear interpolation or nearest neighbor
                            // Nearest neighbor (taking every Nth sample) is often enough for speech ASR
                            // but let's do simple index mapping
                            const offset = Math.floor(i * ratio);
                            result[i] = inputData[offset];
                        }
                        ws.send(result.buffer);
                    }
                }
            };

            input.connect(scriptProcessor);
            scriptProcessor.connect(audioContext.destination);
        }


    </script>
</body>
</html>
